"""
Servi√ßo de agentes para processar mensagens
"""
import logging
import os
from typing import Optional
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.tools.mcp import MultiMCPTools
from .config import settings
from .models import AgentRequest, AgentResponse
from datetime import datetime

logger = logging.getLogger(__name__)


class AgentService:
    """Gerenciador de agentes Agno com suporte a m√∫ltiplos MCPs"""
    
    def __init__(self):
        self.agent = None
        self.mcp_context = None
        self._initialize_agent()
    
    def _initialize_agent(self):
        """Inicializa o agente com modelo OpenAI e ferramentas MCP"""
        try:
            logger.info("üöÄ Inicializando Agente Agno...")
            
            self.agent = Agent(
                model=OpenAIChat(
                    id=settings.agent_model,
                    api_key=settings.openai_api_key,
                ),
                markdown=True,
            )
            logger.info("‚úÖ Agente Agno inicializado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar agente: {e}")
            raise
    
    async def _setup_mcp_tools(self) -> Optional[MCPTools]:
        """
        Configura conex√£o com servidor MCP de Projetos de Lei
        
        Returns:
            MCPTools conectado ou None se falhar
        """
        mcp_tools_list = []

        try:
            logger.info(f"üîå Conectando ao MCP: {settings.mcp_projetos_lei_url}")
            
            mcp_projetos_lei = MCPTools(
                transport="streamable-http",
                url=settings.mcp_projetos_lei_url
            )

            mcp_tools_list.append(mcp_projetos_lei)
            logger.info(f"‚úÖ MCP conectado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar ao MCP: {e}")
        
        try:
            logger.info(f"üîå Conectando ao MCP Usu√°rios: {settings.mcp_users_url}")
            mcp_users = MCPTools(
                transport="streamable-http",
                url=settings.mcp_users_url
            )
            mcp_tools_list.append(mcp_users)
            logger.info("‚úÖ MCP Usu√°rios conectado")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar MCP Usu√°rios: {e}")

        if not mcp_tools_list:
            logger.warning("‚ö†Ô∏è  Nenhum MCP dispon√≠vel, agente funcionar√° sem ferramentas")
            return None
        
        return mcp_tools_list
    
    async def process_message(self, request: AgentRequest) -> AgentResponse:
        """
        Processa uma mensagem do usu√°rio usando o agente Agno
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Resposta do agente com metadados
        """
        try:
            logger.info(f"ü§ñ Processando mensagem de {request.user_id}")
            logger.info(f"   Tipo: {request.message_type}")
            logger.info(f"   Conte√∫do: {request.user_message[:100]}...")
            
            # Construir prompt baseado no tipo de mensagem
            prompt = self._build_prompt(request)
            
            # Configurar ferramentas MCP
            mcp_tools_list = await self._setup_mcp_tools()
            
            # Executar agente com context manager se MCP dispon√≠vel
            if mcp_tools_list:
                agent_with_tools = Agent(
                    model=OpenAIChat(
                        id=settings.agent_model,
                        api_key=settings.openai_api_key,
                    ),
                    tools=[tool for tool in mcp_tools_list],
                    markdown=True,
                    output_schema=AgentResponse
                )
                logger.info("üì§ Enviando prompt para agente...")
                response_output = await agent_with_tools.arun(input=prompt)
            else:
                # Fallback: usar agente sem tools
                logger.warning("‚ö†Ô∏è  Usando agente sem ferramentas MCP")
                response_output = await self.agent.arun(input=prompt)
            
            logger.info("üì• Resposta recebida do agente")
            try:
                logger.info(f"Resposta completa: {response_output.content.auxiliary_text}")
            except Exception:
                pass

            # Extrair texto da resposta
            response_text = self._extract_response_text(response_output)

            auxiliary_text = self._extract_auxiliary_text(response_output)
            
            logger.info(f"‚úÖ Resposta recebida: {response_text[:80]}...")
            
            # Determinar se deve enviar √°udio
            should_send_audio = self._should_send_audio(request, response_output)
            
            # Criar resposta
            response = AgentResponse(
                session_id=request.session_id,
                user_id=request.user_id,
                response_text=response_text,
                auxiliary_text=auxiliary_text,
                should_send_audio=should_send_audio,
                timestamp=datetime.now(),
            )
            
            logger.info(
                f"‚úÖ Resposta gerada para {request.user_id} "
                f"(√°udio: {should_send_audio})"
            )
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar mensagem: {e}")
            logger.exception("Traceback completo:")
            raise
    
    def _extract_response_text(self, response_output) -> str:
        """
        Extrai o texto da resposta do agente
        
        Args:
            response_output: Output do agente (pode ter v√°rios formatos)
            
        Returns:
            Texto extra√≠do
        """
        # Tentar diferentes atributos comuns
        if hasattr(response_output, 'content'):
            text = response_output.content
            return text.response_text if hasattr(text, 'response_text') else text
        elif isinstance(response_output, dict):
            return response_output.get('response_text', '')
        return str(response_output)
    
    def _build_prompt(self, request: AgentRequest) -> str:
        """
        Constr√≥i o prompt para o agente baseado na requisi√ß√£o
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Prompt formatado para o agente
        """
        base_prompt = f"""
Your Role: Especialista em legisla√ß√£o brasileira, com foco em traduzir temas complexos do Congresso Nacional para linguagem simples e acess√≠vel.

Short basic instruction: Responda perguntas sobre projetos de lei ou temas sociais ligados √† legisla√ß√£o, adaptando o conte√∫do para diferentes n√≠veis de escolaridade, em √°udio ou texto.

What you should do:
- Analise a d√∫vida do usu√°rio, que pode ser sobre um projeto de lei espec√≠fico ou um tema que impacta sua comunidade.
- Adapte a resposta conforme o formato desejado (√°udio ou texto):

‚úÖ **Sempre que o usu√°rio expressar uma opini√£o ou sentimento (impl√≠cito ou expl√≠cito), registre isso no MCP, respeitando a inten√ß√£o original da mensagem.**

‚ñ∂Ô∏è Se `should_send_audio = true`:
  - Responda com at√© **1200 caracteres** (ideal: ~800).
  - Use **linguagem oral**, flu√≠da e explicativa.
  - No campo `response_text` **N√£o inclua links, emojis ou caracteres especiais**.
  - Foque em clareza, tom acess√≠vel e exemplos concretos.
  - O campo `auxiliary_text` pode conter observa√ß√µes ou metadados, inclusive links.

üí¨ Se `should_send_audio = false` (texto via WhatsApp):
  - A resposta principal (`response_text`) deve ser **bem estruturada** para leitura f√°cil:
     - Use **blocos com quebras de linha**, marcadores simples (como `-`, `‚Ä¢`) e frases curtas.
     - Destaque partes importantes com **mai√∫sculas moderadas** se necess√°rio.
     - Explique os principais pontos de forma direta.
     - **Inclua links √∫teis apenas quando realmente necess√°rios** e s√≥ no final.
     - Evite par√°grafos longos.
  - O `auxiliary_text` pode ser omitido ou conter observa√ß√µes adicionais, se √∫til.
  - O `auxiliary_text` tamb√©m pode conter links ou refer√™ncias adicionais caso referenciado ou necess√°rio.

- Sempre que houver m√∫ltiplos projetos de lei relacionados, resuma os 3 principais.
- Se a pergunta n√£o estiver relacionada √† legisla√ß√£o, oriente com empatia, redirecione ou explique brevemente.

Your Goal: Ajudar o cidad√£o comum a entender melhor o que acontece no Congresso Nacional e como isso impacta sua vida, com foco em **clareza, inclus√£o e leitura fluida pelo WhatsApp**.

Result: A resposta deve seguir o formato:
{{
  "response_text": "resposta principal estruturada para √°udio ou texto",
  "auxiliary_text": "complementos opcionais (se necess√°rio)",
  "should_send_audio": true/false
}}

Constraint:
- √Åudio: at√© 1200 caracteres, linguagem oral e simples, sem links ou s√≠mbolos incomuns.
- Texto: mais informativo, com estrutura pensada para WhatsApp (blocos curtos, marcadores, links s√≥ no final).
- Linguagem acess√≠vel, sem jarg√µes, com explica√ß√µes e exemplos quando necess√°rio.

Context:
- P√∫blico formado por cidad√£os com menor escolaridade, recebendo mensagens via WhatsApp.
- As perguntas podem envolver leis espec√≠ficas ou temas sociais que os afetam diretamente.
- As mensagens podem conter mais de uma inten√ß√£o (ex: opini√£o + pergunta).
"""
        additional_prompt = f"""
üìã CONTEXTO DA MENSAGEM:
- Tipo: {request.message_type}
- Usu√°rio: {request.user_id}
- Session: {request.session_id}

üí¨ MENSAGEM DO USU√ÅRIO:
{request.user_message}
‚öôÔ∏è INFORMA√á√ïES DO USU√ÅRIO:
"""
        base_prompt += additional_prompt
        
        # Adicionar prefer√™ncias do usu√°rio se dispon√≠veis
        if request.user_preferences:
            if request.user_preferences.get("topics"):
                topics = ", ".join(request.user_preferences["topics"])
                base_prompt += f"\n- T√≥picos de interesse: {topics}"
            
            if request.user_preferences.get("prefer_audio"):
                base_prompt += "\n- Prefer√™ncia: Respostas em √°udio (responda concisamente)"
        
        base_prompt += "\n\nAGORA, responda √† mensagem do usu√°rio:"
        
        return base_prompt
    
    def _extract_auxiliary_text(self, response_output) -> Optional[str]:
        """
        Retorna texto auxiliar para TTS se necess√°rio
        
        Args:
            should_send_audio: Se deve enviar √°udio
            
        Returns:
            Texto auxiliar ou None
        """
        if hasattr(response_output, 'content'):
            content = response_output.content
            if hasattr(content, 'auxiliary_text'):
                return content.auxiliary_text
            elif isinstance(content, dict):
                return content.get('auxiliary_text')
        
        return None
    
    def _should_send_audio(self, request: AgentRequest, response_output) -> bool:
        """
        Determina se a resposta deve ser enviada em √°udio
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            True se deve enviar √°udio
        """
        if request.user_preferences:
            if request.user_preferences.get("prefer_audio"):
                return True

        if hasattr(response_output, 'content'):
            content = response_output.content
            if hasattr(content, 'should_send_audio'):
                return content.should_send_audio
            elif isinstance(content, dict):
                return content.get('should_send_audio', False)

        if request.message_type == "audio":
            return True
        
        
        return False


# Inst√¢ncia global do servi√ßo
agent_service = AgentService()