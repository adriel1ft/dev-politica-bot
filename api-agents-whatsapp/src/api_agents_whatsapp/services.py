"""
Servi√ßo de agentes para processar mensagens
"""
import logging
import os
from typing import Optional
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.tools.mcp import MultiMCPTools
from .config import settings
from .models import AgentRequest, AgentResponse
from datetime import datetime

logger = logging.getLogger(__name__)


class AgentService:
    """Gerenciador de agentes Agno com suporte a m√∫ltiplos MCPs"""
    
    def __init__(self):
        self.agent = None
        self.mcp_context = None
        self._initialize_agent()
    
    def _initialize_agent(self):
        """Inicializa o agente com modelo OpenAI e ferramentas MCP"""
        try:
            logger.info("üöÄ Inicializando Agente Agno...")
            
            self.agent = Agent(
                model=OpenAIChat(
                    id=settings.agent_model,
                    api_key=settings.openai_api_key,
                ),
                markdown=True,
            )
            logger.info("‚úÖ Agente Agno inicializado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar agente: {e}")
            raise
    
    async def _setup_mcp_tools(self) -> Optional[MCPTools]:
        """
        Configura conex√£o com servidor MCP de Projetos de Lei
        
        Returns:
            MCPTools conectado ou None se falhar
        """
        mcp_tools_list = []

        try:
            logger.info(f"üîå Conectando ao MCP: {settings.mcp_projetos_lei_url}")
            
            mcp_projetos_lei = MCPTools(
                transport="streamable-http",
                url=settings.mcp_projetos_lei_url
            )

            mcp_tools_list.append(mcp_projetos_lei)
            logger.info(f"‚úÖ MCP conectado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar ao MCP: {e}")
        
        try:
            logger.info(f"üîå Conectando ao MCP Usu√°rios: {settings.mcp_users_url}")
            mcp_users = MCPTools(
                transport="streamable-http",
                url=settings.mcp_users_url
            )
            mcp_tools_list.append(mcp_users)
            logger.info("‚úÖ MCP Usu√°rios conectado")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar MCP Usu√°rios: {e}")

        if not mcp_tools_list:
            logger.warning("‚ö†Ô∏è  Nenhum MCP dispon√≠vel, agente funcionar√° sem ferramentas")
            return None
        
        return mcp_tools_list
    
    async def process_message(self, request: AgentRequest) -> AgentResponse:
        """
        Processa uma mensagem do usu√°rio usando o agente Agno
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Resposta do agente com metadados
        """
        try:
            logger.info(f"ü§ñ Processando mensagem de {request.user_id}")
            logger.info(f"   Tipo: {request.message_type}")
            logger.info(f"   Conte√∫do: {request.user_message[:100]}...")
            
            # Construir prompt baseado no tipo de mensagem
            prompt = self._build_prompt(request)
            
            # Configurar ferramentas MCP
            mcp_tools_list = await self._setup_mcp_tools()
            
            # Executar agente com context manager se MCP dispon√≠vel
            if mcp_tools_list:
                agent_with_tools = Agent(
                    model=OpenAIChat(
                        id=settings.agent_model,
                        api_key=settings.openai_api_key,
                    ),
                    tools=[tool for tool in mcp_tools_list],
                    markdown=True,
                    output_schema=AgentResponse
                )
                logger.info("üì§ Enviando prompt para agente...")
                response_output = await agent_with_tools.arun(input=prompt)
            else:
                # Fallback: usar agente sem tools
                logger.warning("‚ö†Ô∏è  Usando agente sem ferramentas MCP")
                response_output = await self.agent.arun(input=prompt)
            
            logger.info("üì• Resposta recebida do agente")
            try:
                logger.info(f"Resposta completa: {response_output.content.auxiliary_text}")
            except Exception:
                pass

            # Extrair texto da resposta
            response_text = self._extract_response_text(response_output)

            auxiliary_text = self._extract_auxiliary_text(response_output)
            
            logger.info(f"‚úÖ Resposta recebida: {response_text[:80]}...")
            
            # Determinar se deve enviar √°udio
            should_send_audio = self._should_send_audio(request, response_output)
            
            # Criar resposta
            response = AgentResponse(
                session_id=request.session_id,
                user_id=request.user_id,
                response_text=response_text,
                auxiliary_text=auxiliary_text,
                should_send_audio=should_send_audio,
                timestamp=datetime.now(),
            )
            
            logger.info(
                f"‚úÖ Resposta gerada para {request.user_id} "
                f"(√°udio: {should_send_audio})"
            )
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar mensagem: {e}")
            logger.exception("Traceback completo:")
            raise
    
    def _extract_response_text(self, response_output) -> str:
        """
        Extrai o texto da resposta do agente
        
        Args:
            response_output: Output do agente (pode ter v√°rios formatos)
            
        Returns:
            Texto extra√≠do
        """
        # Tentar diferentes atributos comuns
        if hasattr(response_output, 'content'):
            text = response_output.content
            return text.response_text if hasattr(text, 'response_text') else text
        elif isinstance(response_output, dict):
            return response_output.get('response_text', '')
        return str(response_output)
    
    def _build_prompt(self, request: AgentRequest) -> str:
        """
        Constr√≥i o prompt para o agente baseado na requisi√ß√£o
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Prompt formatado para o agente
        """
        base_prompt = f"""
Your Role: Especialista em legisla√ß√£o brasileira, com foco em traduzir temas complexos do Congresso Nacional para linguagem simples e acess√≠vel.

Short basic instruction: Responda perguntas sobre projetos de lei ou temas que impactam comunidades, adaptando a linguagem para pessoas com menor escolaridade.

What you should do:
- Analise a pergunta do usu√°rio, que pode ser sobre um projeto de lei espec√≠fico ou sobre um tema que afeta sua comunidade.
- Responda com linguagem simples, clara e acess√≠vel, adaptando o tom e o n√≠vel de detalhe ao tipo de resposta (√°udio ou texto).
- Se for **√°udio** (`should_send_audio = true`):
   - A resposta principal (`response_text`) deve ter at√© 1200 caracteres (ideal: ~800).
   - Use linguagem oral, flu√≠da e expositiva, com explica√ß√µes simples e exemplos se necess√°rio.
   - **N√£o inclua links, emojis ou caracteres especiais**. 
   - O campo `auxiliary_text` deve conter observa√ß√µes extras ou complementares, caso precise. Tamb√©m
   pode ser usado para destacar pontos importantes, fornecer contexto adicional ou incluir links.
- Se for **texto** (`should_send_audio = false`):
   - A resposta principal (`response_text`) deve conter mais informa√ß√µes, explica√ß√µes adicionais e, se necess√°rio, links √∫teis para fontes confi√°veis (e-Cidadania, C√¢mara dos Deputados etc).
   - O `auxiliary_text` pode ser omitido ou usado para contextualizar ou destacar pontos relevantes.

Your Goal: Facilitar o entendimento de temas legislativos, aproximando o cidad√£o do Congresso Nacional, usando uma linguagem que respeite o n√≠vel de instru√ß√£o do p√∫blico.

Constraint:
- Em √°udio: at√© 1200 caracteres, tom expositivo e acess√≠vel.
- Em texto: mais completo e informativo.
- Sem jarg√µes t√©cnicos. Use exemplos e explique termos dif√≠ceis.
- Links e fontes s√≥ quando realmente agregarem.

Context:
- O p√∫blico √© formado por cidad√£os de diferentes regi√µes, muitos com baixa escolaridade.
- As perguntas podem ser sobre projetos de lei espec√≠ficos ou temas que afetam diretamente a comunidade (mesmo que a rela√ß√£o com a lei n√£o seja clara).
- O atendimento √© feito via WhatsApp.
"""
        additional_prompt = f"""
üìã CONTEXTO DA MENSAGEM:
- Tipo: {request.message_type}
- Usu√°rio: {request.user_id}
- Session: {request.session_id}

üí¨ MENSAGEM DO USU√ÅRIO:
{request.user_message}
‚öôÔ∏è INFORMA√á√ïES DO USU√ÅRIO:
"""
        base_prompt += additional_prompt
        
        # Adicionar prefer√™ncias do usu√°rio se dispon√≠veis
        if request.user_preferences:
            if request.user_preferences.get("topics"):
                topics = ", ".join(request.user_preferences["topics"])
                base_prompt += f"\n- T√≥picos de interesse: {topics}"
            
            if request.user_preferences.get("prefer_audio"):
                base_prompt += "\n- Prefer√™ncia: Respostas em √°udio (responda concisamente)"
        
        base_prompt += "\n\nAGORA, responda √† mensagem do usu√°rio:"
        
        return base_prompt
    
    def _extract_auxiliary_text(self, response_output) -> Optional[str]:
        """
        Retorna texto auxiliar para TTS se necess√°rio
        
        Args:
            should_send_audio: Se deve enviar √°udio
            
        Returns:
            Texto auxiliar ou None
        """
        if hasattr(response_output, 'content'):
            content = response_output.content
            if hasattr(content, 'auxiliary_text'):
                return content.auxiliary_text
            elif isinstance(content, dict):
                return content.get('auxiliary_text')
        
        return None
    
    def _should_send_audio(self, request: AgentRequest, response_output) -> bool:
        """
        Determina se a resposta deve ser enviada em √°udio
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            True se deve enviar √°udio
        """
        if request.user_preferences:
            if request.user_preferences.get("prefer_audio"):
                return True

        if hasattr(response_output, 'content'):
            content = response_output.content
            if hasattr(content, 'should_send_audio'):
                return content.should_send_audio
            elif isinstance(content, dict):
                return content.get('should_send_audio', False)

        if request.message_type == "audio":
            return True
        
        
        return False


# Inst√¢ncia global do servi√ßo
agent_service = AgentService()